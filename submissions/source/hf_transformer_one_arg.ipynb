{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hf_transformer_one_arg.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1TraR4Xk6424qhZWN9eT4wQY1XecvvSc_","authorship_tag":"ABX9TyO+m8LC31w95IT6wh0aVgR2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"93a57136674f474392663230f325c4b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_633467f849fe4a3e8de3637932e0a099","IPY_MODEL_2a90a393a0de42338ebfd914dceb3320","IPY_MODEL_a4416ddf5e26418fa405bdb84a22ce1e"],"layout":"IPY_MODEL_e83afc3a6b014b5e94fc89b407953fb1"}},"633467f849fe4a3e8de3637932e0a099":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39dda60ebe4141c797a62226096705c2","placeholder":"​","style":"IPY_MODEL_35cf0d8d754a430596e57843ca875f5d","value":"100%"}},"2a90a393a0de42338ebfd914dceb3320":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5ff76de919940ffb2e54c0e9e1fa926","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c36e92fa4aed4696b22cb1c57305d0cd","value":13}},"a4416ddf5e26418fa405bdb84a22ce1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2315797c2b5a42d1ad737fa798e6ce54","placeholder":"​","style":"IPY_MODEL_82f6977986f0438ca97bcf444244b12b","value":" 13/13 [00:03&lt;00:00,  3.90ba/s]"}},"e83afc3a6b014b5e94fc89b407953fb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39dda60ebe4141c797a62226096705c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35cf0d8d754a430596e57843ca875f5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5ff76de919940ffb2e54c0e9e1fa926":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c36e92fa4aed4696b22cb1c57305d0cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2315797c2b5a42d1ad737fa798e6ce54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82f6977986f0438ca97bcf444244b12b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa57ea2501f94e43954de3539a9867d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a4e0252fbe241c7abbd81843ca7c96c","IPY_MODEL_e1bba91040454e4abaebb6779007d0ed","IPY_MODEL_cd5d64ce5db7465ca163bf1803931430"],"layout":"IPY_MODEL_9c4650aa349345b18cb3465423179a2c"}},"4a4e0252fbe241c7abbd81843ca7c96c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d183afac3b84301b4a154b48671e5b4","placeholder":"​","style":"IPY_MODEL_c1ee8fa766a2479fa15d58d600add583","value":"100%"}},"e1bba91040454e4abaebb6779007d0ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3fb2b87188c4316b4d28f6fc34af2f2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30930a78a9c74a2094e6032bd3651d36","value":1}},"cd5d64ce5db7465ca163bf1803931430":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec374ab7fbf040229a2287d8d7bd5452","placeholder":"​","style":"IPY_MODEL_799c4df1a1bc495397e8be07a0bd2248","value":" 1/1 [00:00&lt;00:00,  6.84ba/s]"}},"9c4650aa349345b18cb3465423179a2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d183afac3b84301b4a154b48671e5b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1ee8fa766a2479fa15d58d600add583":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3fb2b87188c4316b4d28f6fc34af2f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30930a78a9c74a2094e6032bd3651d36":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec374ab7fbf040229a2287d8d7bd5452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"799c4df1a1bc495397e8be07a0bd2248":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1374ba19366b479685cb0471450a697f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8714f85bba6247469a2f30108bbc499a","IPY_MODEL_b6993be573aa418d98f9b2360e85842f","IPY_MODEL_b9a1c11be7e84ecdac29b9f816c6976b"],"layout":"IPY_MODEL_8ef8e8ebdcd649fdbc11bf459cad5e70"}},"8714f85bba6247469a2f30108bbc499a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_938dc2d120654c1b83a7c4f775485d10","placeholder":"​","style":"IPY_MODEL_e56f839d81bc4d6fb546fe13011aed4f","value":"100%"}},"b6993be573aa418d98f9b2360e85842f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c36f18f17a604057b7b7942bbb615b48","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18144633b39b4e35910a91a1b28b1f68","value":1}},"b9a1c11be7e84ecdac29b9f816c6976b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7d2dae989e64c3c80083aae444e7c9f","placeholder":"​","style":"IPY_MODEL_d2ac53b96686461aa9cf627c7ffd9c6c","value":" 1/1 [00:00&lt;00:00,  4.79ba/s]"}},"8ef8e8ebdcd649fdbc11bf459cad5e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"938dc2d120654c1b83a7c4f775485d10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e56f839d81bc4d6fb546fe13011aed4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c36f18f17a604057b7b7942bbb615b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18144633b39b4e35910a91a1b28b1f68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7d2dae989e64c3c80083aae444e7c9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2ac53b96686461aa9cf627c7ffd9c6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0Y_dMYviKG5","executionInfo":{"status":"ok","timestamp":1651458087908,"user_tz":240,"elapsed":14992,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"175539c6-dcfe-4b6d-f016-b387086f85f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n","\u001b[K     |████████████████████████████████| 325 kB 32.5 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 59.6 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 66.8 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 67.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 8.3 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 69.6 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 65.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 67.0 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 62.1 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 75.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 68.0 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=b4b1c5efc527bc2c44bf740c363a152515c1d719d8882562282a9dfaf10197cb\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, responses, huggingface-hub, transformers, seqeval, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 seqeval-1.2.2 tokenizers-0.12.1 transformers-4.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["! pip install datasets transformers seqeval"]},{"cell_type":"code","source":["from pathlib import Path\n","from argparse import Namespace\n","from typing import Union, List\n","from fastprogress import progress_bar\n","from typing_extensions import TypedDict\n","import torch\n","from datasets import Dataset, DatasetDict, load_metric\n","import numpy as np\n","from transformers import DataCollatorForTokenClassification, AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n"],"metadata":{"id":"bOZi_M3pk2So","executionInfo":{"status":"ok","timestamp":1651458112881,"user_tz":240,"elapsed":6275,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data_dir = Path(\"/content/drive/Shareddrives/derzart@gmail.com/studies/nlp-final-project/data\")\n","\n","args = Namespace(\n","    batch_size=64,\n","    num_workers=4\n",")\n","\n","train_data_path = data_dir / 'total-training'\n","valid_data_path = data_dir / 'total-dev'\n","test_data_path = data_dir / 'total-test'"],"metadata":{"id":"94x-4FbJk0HC","executionInfo":{"status":"ok","timestamp":1651460598297,"user_tz":240,"elapsed":237,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["SYMBOL_DICT = {\n","    \"COMMA\": \",\",\n","}\n","\n","LABEL_LIST = [\"NONE\", \"PRED\", \"ARG1\", \"SUPPORT\"]\n","POS_LIST = [\"CC\", \"CD\", \"DT\", \"FW\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \n","            \"LS\", \"MD\", \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \n","            \"POS\", \"PRP\", \"PRP$\", \"RB\", \"RBR\", \"RBS\", \"SYM\", \n","            \"TO\", \"UH\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\",\n","            \"VBZ\", \"WDT\", \"WP\", \"WP$\", \"WRB\", \"PU\", \"EX\", \n","            \"RP\", \"AUX\"]\n","BIO_TAG_CONVERSION_DICT = {\n","    \".\": \"PU\",\n","    \",\": \"PU\",\n","    \"COMMA\": \"PU\",\n","    \"$\": \"PU\",\n","    \":\": \"PU\",\n","    \"(\": \"PU\",\n","    \")\": \"PU\",\n","    \"``\": \"PU\",\n","    \"''\": \"PU\",\n","    \"#\": \"PU\",\n","    \"/\": \"PU\",\n","    \"-\": \"PU\",\n","\n","}\n","BIO_TAG_LIST = [\"O\", \"B-NP\", \"I-NP\", \"B-VP\", \"I-VP\", \"B-PP\",\n","                \"I-PP\", \"B-ADJP\", \"I-ADJP\", \"B-ADVP\", \"I-ADVP\",\n","                \"B-SBAR\", \"I-SBAR\", \"B-PRT\", \"I-PRT\", \"B-CONJP\",\n","                \"I-CONJP\", \"B-UCP\", \"I-UCP\", \"B-LST\", \"I-LST\", \"B-INTJ\", \"I-INTJ\"]"],"metadata":{"id":"YPjWInYIiSXV","executionInfo":{"status":"ok","timestamp":1651460598957,"user_tz":240,"elapsed":1,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["class Word(TypedDict):\n","  word: str\n","  pos: str\n","  biotag: str\n","  label: Union[str, None]\n","\n","def parse_input(input_file: Union[str, Path], drop_label = False) -> List[Union[List[Word], None]]:\n","    \"\"\"\n","    Parses the input file and returns a list of lists of words.\n","    \"\"\"\n","    with open(input_file, \"r\") as f:\n","        lines = f.readlines()\n","    sentences: List[Union[List[Word], None]] = []\n","    last_sentence: List[Word] = []\n","    print(\"Parsing input file lines...\")\n","    line_no = 0\n","    for line in progress_bar(lines):\n","        line_no += 1\n","        line = line.strip()\n","        word_info = line.split(\"\\t\")\n","        if len(word_info) >= 5:\n","            word_str = word_info[0].strip()\n","            if word_str in SYMBOL_DICT:\n","              word_str = SYMBOL_DICT[word_str]\n","            pos = word_info[1].strip()\n","            if pos in BIO_TAG_CONVERSION_DICT:\n","              pos = BIO_TAG_CONVERSION_DICT[pos]\n","            if pos not in POS_LIST:\n","              print(f\"Warning: invalid POS on line {line_no} \\\"{pos}\\\", treated as PU.\")\n","              pos = \"PU\"\n","            biotag = word_info[2].strip()\n","            if biotag not in BIO_TAG_LIST:\n","              print(f\"Warning: invalid bio tag on line {line_no} \\\"{biotag}\\\", treated as O.\")\n","              biotag = \"O\"\n","            if len(word_info) >= 6:\n","                label = word_info[5].strip()\n","            else:\n","                label = \"NONE\"\n","            if label not in LABEL_LIST:\n","              print(f\"Warning: invalid label on line {line_no} \\\"{label}\\\", treated as NONE.\")\n","              label = \"NONE\"\n","            if drop_label:\n","              label = None\n","            word = Word(word=word_str, pos=pos, biotag=biotag, label=label)\n","            last_sentence.append(word)\n","        else:\n","            if len(last_sentence) > 0:\n","                sentences.append(last_sentence)\n","            last_sentence = []\n","    if len(last_sentence) > 0:\n","        sentences.append(last_sentence)\n","    return sentences"],"metadata":{"id":"BXoIpNI0kuzk","executionInfo":{"status":"ok","timestamp":1651460600043,"user_tz":240,"elapsed":154,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["train_sentences = parse_input(train_data_path)\n","valid_sentences = parse_input(valid_data_path)\n","test_sentences = parse_input(test_data_path, drop_label=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131},"id":"HIBlv6dnlG3K","executionInfo":{"status":"ok","timestamp":1651460603026,"user_tz":240,"elapsed":1579,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"0eaf7edf-e085-4973-b411-676979630086"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Parsing input file lines...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='393238' class='' max='393238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [393238/393238 00:01<00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Parsing input file lines...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='13097' class='' max='13097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [13097/13097 00:00<00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Parsing input file lines...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='22282' class='' max='22282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [22282/22282 00:00<00:00]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(LABEL_LIST))\n","# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","# model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(LABEL_LIST))\n","# tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n","# model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\", num_labels=len(LABEL_LIST))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DWGPQhiUO3Al","executionInfo":{"status":"ok","timestamp":1651460606467,"user_tz":240,"elapsed":2150,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"89447b4b-1dd2-4943-8926-2f7fbe36c173"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def build_dataset_from_sentences(sentences, drop_label = False):\n","  dataset_tokens = []\n","  dataset_partitive_roles = []\n","  dataset_pos_tags = []\n","  dataset_bio_tags = []\n","  for sentence in sentences:\n","    tokens = [word['word'] for word in sentence]\n","    if not drop_label:\n","      partitive_roles = [LABEL_LIST.index(word['label']) for word in sentence]\n","    else:\n","      partitive_roles = None\n","    pos_tags = [POS_LIST.index(word['pos']) for word in sentence]\n","    bio_tags = [BIO_TAG_LIST.index(word['biotag']) for word in sentence]\n","    dataset_tokens.append(tokens)\n","    if not drop_label:\n","      dataset_partitive_roles.append(partitive_roles)\n","    dataset_pos_tags.append(pos_tags)\n","    dataset_bio_tags.append(bio_tags)\n","  if not drop_label:\n","    dataset_dict = {\n","        \"tokens\": dataset_tokens,\n","        \"partitive_roles\": dataset_partitive_roles,\n","        \"pos_tags\": dataset_pos_tags,\n","        \"bio_tags\": dataset_bio_tags\n","    }\n","  else:\n","    dataset_dict = {\n","        \"tokens\": dataset_tokens,\n","        \"pos_tags\": dataset_pos_tags,\n","        \"bio_tags\": dataset_bio_tags\n","    }\n","  return Dataset.from_dict(dataset_dict)"],"metadata":{"id":"M2-5Tq_NHrRb","executionInfo":{"status":"ok","timestamp":1651460610224,"user_tz":240,"elapsed":175,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["train_raw_dataset = build_dataset_from_sentences(train_sentences)\n","valid_raw_dataset = build_dataset_from_sentences(valid_sentences)\n","test_raw_dataset = build_dataset_from_sentences(test_sentences, drop_label=True)\n","\n","raw_datasets = DatasetDict(train=train_raw_dataset, valid=valid_raw_dataset, test=test_raw_dataset)"],"metadata":{"id":"SfdQwtaeW3wo","executionInfo":{"status":"ok","timestamp":1651460614039,"user_tz":240,"elapsed":1023,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["label_all_tokens = True\n","\n","def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], is_split_into_words=True)\n","\n","    if \"partitive_roles\" in examples:\n","      labels = []\n","      for i, label in enumerate(examples[\"partitive_roles\"]):\n","          word_ids = tokenized_inputs.word_ids(batch_index=i)\n","          previous_word_idx = None\n","          label_ids = []\n","          for word_idx in word_ids:\n","              # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","              # ignored in the loss function.\n","              if word_idx is None:\n","                  label_ids.append(-100)\n","              # We set the label for the first token of each word.\n","              elif word_idx != previous_word_idx:\n","                  label_ids.append(label[word_idx])\n","              # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","              # the label_all_tokens flag.\n","              else:\n","                  label_ids.append(label[word_idx] if label_all_tokens else -100)\n","              previous_word_idx = word_idx\n","\n","          labels.append(label_ids)\n","\n","      tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"],"metadata":{"id":"d6bUZKiYeA6R","executionInfo":{"status":"ok","timestamp":1651460620317,"user_tz":240,"elapsed":299,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets = raw_datasets.map(tokenize_and_align_labels, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["93a57136674f474392663230f325c4b0","633467f849fe4a3e8de3637932e0a099","2a90a393a0de42338ebfd914dceb3320","a4416ddf5e26418fa405bdb84a22ce1e","e83afc3a6b014b5e94fc89b407953fb1","39dda60ebe4141c797a62226096705c2","35cf0d8d754a430596e57843ca875f5d","e5ff76de919940ffb2e54c0e9e1fa926","c36e92fa4aed4696b22cb1c57305d0cd","2315797c2b5a42d1ad737fa798e6ce54","82f6977986f0438ca97bcf444244b12b","aa57ea2501f94e43954de3539a9867d4","4a4e0252fbe241c7abbd81843ca7c96c","e1bba91040454e4abaebb6779007d0ed","cd5d64ce5db7465ca163bf1803931430","9c4650aa349345b18cb3465423179a2c","7d183afac3b84301b4a154b48671e5b4","c1ee8fa766a2479fa15d58d600add583","a3fb2b87188c4316b4d28f6fc34af2f2","30930a78a9c74a2094e6032bd3651d36","ec374ab7fbf040229a2287d8d7bd5452","799c4df1a1bc495397e8be07a0bd2248","1374ba19366b479685cb0471450a697f","8714f85bba6247469a2f30108bbc499a","b6993be573aa418d98f9b2360e85842f","b9a1c11be7e84ecdac29b9f816c6976b","8ef8e8ebdcd649fdbc11bf459cad5e70","938dc2d120654c1b83a7c4f775485d10","e56f839d81bc4d6fb546fe13011aed4f","c36f18f17a604057b7b7942bbb615b48","18144633b39b4e35910a91a1b28b1f68","f7d2dae989e64c3c80083aae444e7c9f","d2ac53b96686461aa9cf627c7ffd9c6c"]},"id":"3-PU3d8-eI5O","executionInfo":{"status":"ok","timestamp":1651460628282,"user_tz":240,"elapsed":4078,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"c9293fb2-f73c-41ff-963a-12e1feeba9ce"},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/13 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93a57136674f474392663230f325c4b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa57ea2501f94e43954de3539a9867d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1374ba19366b479685cb0471450a697f"}},"metadata":{}}]},{"cell_type":"code","source":["def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [LABEL_LIST[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [LABEL_LIST[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"],"metadata":{"id":"h_XkCb8RH2b-","executionInfo":{"status":"ok","timestamp":1651460631976,"user_tz":240,"elapsed":125,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["batch_size=64\n","\n","train_args = TrainingArguments(\n","    \"bert_partitive_roles\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=10,\n","    weight_decay=0.01\n",")\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)\n","\n","metric = load_metric(\"seqeval\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrINNbmvM4h8","executionInfo":{"status":"ok","timestamp":1651460636195,"user_tz":240,"elapsed":323,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"c7f95552-4820-4069-dbbc-0b7c46f1e6d5"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model,\n","    train_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"valid\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"],"metadata":{"id":"B5FK9UrjPOHM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1651461494095,"user_tz":240,"elapsed":848979,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"7bd5ebc2-7795-4311-8f89-c8247e5bdd50"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 12991\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2030\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2030' max='2030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2030/2030 14:08, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.101822</td>\n","      <td>0.648964</td>\n","      <td>0.679476</td>\n","      <td>0.663869</td>\n","      <td>0.960489</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.087744</td>\n","      <td>0.714006</td>\n","      <td>0.659132</td>\n","      <td>0.685472</td>\n","      <td>0.964969</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.129900</td>\n","      <td>0.081521</td>\n","      <td>0.723529</td>\n","      <td>0.667269</td>\n","      <td>0.694262</td>\n","      <td>0.966373</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.129900</td>\n","      <td>0.079768</td>\n","      <td>0.712540</td>\n","      <td>0.711573</td>\n","      <td>0.712056</td>\n","      <td>0.966974</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.064300</td>\n","      <td>0.079575</td>\n","      <td>0.727668</td>\n","      <td>0.681284</td>\n","      <td>0.703712</td>\n","      <td>0.966573</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.064300</td>\n","      <td>0.079197</td>\n","      <td>0.703898</td>\n","      <td>0.726492</td>\n","      <td>0.715017</td>\n","      <td>0.966306</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.064300</td>\n","      <td>0.079966</td>\n","      <td>0.736919</td>\n","      <td>0.681284</td>\n","      <td>0.708010</td>\n","      <td>0.967308</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.053400</td>\n","      <td>0.080367</td>\n","      <td>0.729717</td>\n","      <td>0.699367</td>\n","      <td>0.714220</td>\n","      <td>0.967108</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.053400</td>\n","      <td>0.079870</td>\n","      <td>0.733302</td>\n","      <td>0.699819</td>\n","      <td>0.716169</td>\n","      <td>0.967843</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.049200</td>\n","      <td>0.080448</td>\n","      <td>0.722607</td>\n","      <td>0.706600</td>\n","      <td>0.714514</td>\n","      <td>0.967108</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NONE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRED seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SUPPORT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","Saving model checkpoint to bert_partitive_roles/checkpoint-500\n","Configuration saved in bert_partitive_roles/checkpoint-500/config.json\n","Model weights saved in bert_partitive_roles/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in bert_partitive_roles/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in bert_partitive_roles/checkpoint-500/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NONE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRED seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SUPPORT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","Saving model checkpoint to bert_partitive_roles/checkpoint-1000\n","Configuration saved in bert_partitive_roles/checkpoint-1000/config.json\n","Model weights saved in bert_partitive_roles/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in bert_partitive_roles/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in bert_partitive_roles/checkpoint-1000/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NONE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRED seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SUPPORT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","Saving model checkpoint to bert_partitive_roles/checkpoint-1500\n","Configuration saved in bert_partitive_roles/checkpoint-1500/config.json\n","Model weights saved in bert_partitive_roles/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in bert_partitive_roles/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in bert_partitive_roles/checkpoint-1500/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NONE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRED seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SUPPORT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","Saving model checkpoint to bert_partitive_roles/checkpoint-2000\n","Configuration saved in bert_partitive_roles/checkpoint-2000/config.json\n","Model weights saved in bert_partitive_roles/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in bert_partitive_roles/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in bert_partitive_roles/checkpoint-2000/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, partitive_roles, tokens, pos_tags. If bio_tags, partitive_roles, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 426\n","  Batch size = 64\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NONE seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRED seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SUPPORT seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2030, training_loss=0.07387227830041218, metrics={'train_runtime': 848.7358, 'train_samples_per_second': 153.063, 'train_steps_per_second': 2.392, 'total_flos': 2551122865185432.0, 'train_loss': 0.07387227830041218, 'epoch': 10.0})"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":[" test_results = trainer.predict(tokenized_datasets['test'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":128},"id":"prl-I9Fbi-3R","executionInfo":{"status":"ok","timestamp":1651461506467,"user_tz":240,"elapsed":1728,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"0ce17bab-1a91-45f2-e956-c556fa930c94"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the test set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: bio_tags, tokens, pos_tags. If bio_tags, tokens, pos_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 746\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:01]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["for prediction in test_results.predictions[1]:\n","  index = np.argmax(prediction)\n","  if index == 2:\n","    print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9X_JewJ6dXP5","executionInfo":{"status":"ok","timestamp":1651461509172,"user_tz":240,"elapsed":142,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"98ddacf3-21d9-4b59-b8aa-62ad20419a88"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 0.18880649 -3.379016    5.0952873  -3.018466  ]\n","[ 1.2384644 -2.1803174  2.2015154 -2.3593576]\n"]}]},{"cell_type":"code","source":["np.argmax([1, 5, 3, 5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LbJHRW12moYl","executionInfo":{"status":"ok","timestamp":1651460011380,"user_tz":240,"elapsed":150,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"e41172a5-bd59-4757-eb6e-500ffe948e53"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["out = []\n","\n","for i in range(len(tokenized_datasets['test'])):\n","  sentence = tokenized_datasets['test'][i]\n","  tokenized_input = tokenizer(sentence[\"tokens\"], truncation=True, is_split_into_words=True)\n","  predictions = test_results.predictions[i]\n","  label_ids = []\n","  max_arg1_index = -1\n","  max_arg1_value = -100\n","  for j, prediction in enumerate(predictions):\n","    arg1_value = prediction[2]\n","    if arg1_value > max_arg1_value:\n","      max_arg1_value = arg1_value\n","      max_arg1_index = j\n","  for j, prediction in enumerate(predictions):\n","    label_ids.append(2 if j == max_arg1_index else 0)\n","  word_id_to_label_idx = {}\n","  for j, word_id in enumerate(tokenized_input.word_ids()):\n","    if word_id in word_id_to_label_idx or word_id is None:\n","      continue\n","    word_id_to_label_idx[word_id] = j\n","  labelings = []\n","  has_arg1 = False\n","\n","  for j, token in enumerate(sentence[\"tokens\"]):\n","    label_idx = word_id_to_label_idx[j]\n","    next_label_idx = word_id_to_label_idx[j+1] if j+1 < len(word_id_to_label_idx) else len(label_ids)\n","\n","    is_arg1 = False\n","\n","    for k in range(label_idx, next_label_idx):\n","      label_id = label_ids[k]\n","      if label_id == 2:\n","        is_arg1 = True\n","\n","    label = 'ARG1' if is_arg1 else None\n","    if label == 'ARG1':\n","      has_arg1 = True\n","    if token == ',':\n","      token = 'COMMA'\n","    labelings.append((token, label))\n","  out.append(labelings)\n","\n","  if not has_arg1:\n","    print(f\"line {i} has no arg1\")\n"],"metadata":{"id":"SwwhdgzyCSq2","executionInfo":{"status":"ok","timestamp":1651461513233,"user_tz":240,"elapsed":580,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"662dd065-08a0-4bf3-c946-336328e4fb9c"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["line 694 has no arg1\n"]}]},{"cell_type":"code","source":["arg1_count = 0\n","for labelings in out:\n","  has_arg1 = 0\n","  for token, label in labelings:\n","    if label == 'ARG1':\n","      has_arg1 += 1\n","  if has_arg1 == 1:\n","    arg1_count += 1\n","arg1_count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXXSrAZ2hQZ4","executionInfo":{"status":"ok","timestamp":1651461517076,"user_tz":240,"elapsed":113,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"1e41278a-5d5e-45c1-a5c3-339c4459e7b8"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["745"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["out_path = data_dir / '..' / 'out' / 'test-out-distilbert-one-arg'"],"metadata":{"id":"00hjuQfUlF68","executionInfo":{"status":"ok","timestamp":1651461520261,"user_tz":240,"elapsed":132,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["arg1_count = 0\n","\n","with open(out_path, 'w') as f:\n","  for line in out:\n","    for labling in line:\n","      if labling[1] and labling[1] == 'ARG1':\n","        f.write(f\"{labling[0]}\\t{labling[1]}\\n\")\n","        arg1_count += 1\n","      else:\n","        f.write(f\"{labling[0]}\\n\")\n","    f.write(\"\\n\")\n","\n","arg1_count"],"metadata":{"id":"52qU7BKppwFD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651461562458,"user_tz":240,"elapsed":136,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}},"outputId":"75658ef6-4259-45dd-f034-4ce9ca77b715"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["745"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["test_set = 'test'"],"metadata":{"id":"jzNfZnd3tX-e","executionInfo":{"status":"ok","timestamp":1651461537458,"user_tz":240,"elapsed":109,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["out = []\n","\n","for i in range(len(tokenized_datasets[test_set])):\n","  sentence = tokenized_datasets[test_set][i]\n","  tokenized_input = tokenizer(sentence[\"tokens\"], truncation=True, is_split_into_words=True)\n","  predictions = test_results.predictions[i]\n","  label_ids = []\n","  for prediction in predictions:\n","    label_ids.append(np.argmax(prediction))\n","  word_id_to_label_idx = {}\n","  for j, word_id in enumerate(tokenized_input.word_ids()):\n","    if word_id in word_id_to_label_idx or word_id is None:\n","      continue\n","    word_id_to_label_idx[word_id] = j\n","  labelings = []\n","  for j, token in enumerate(sentence[\"tokens\"]):\n","    label_idx = word_id_to_label_idx[j]\n","    label_id = label_ids[label_idx]\n","    label = LABEL_LIST[label_id] if label_id != 0 else None\n","    labelings.append((token, label))\n","  out.append(labelings)\n"],"metadata":{"id":"RTs25TU8nl_8","executionInfo":{"status":"ok","timestamp":1651460378517,"user_tz":240,"elapsed":880,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["out_path = data_dir / '..' / 'out' / 'test-out-distilbert'"],"metadata":{"id":"vjzjlDkHtD-n","executionInfo":{"status":"ok","timestamp":1651460400392,"user_tz":240,"elapsed":200,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["with open(out_path, 'w') as f:\n","  for line in out:\n","    for labling in line:\n","      if labling[1]:\n","        f.write(f\"{labling[0]}\\t{labling[1]}\\n\")\n","      else:\n","        f.write(f\"{labling[0]}\\n\")\n","    f.write(\"\\n\")"],"metadata":{"id":"lnQiD3wfteIn","executionInfo":{"status":"ok","timestamp":1651460446320,"user_tz":240,"elapsed":233,"user":{"displayName":"Derzart Ampere","userId":"06480489264663714311"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"J8MacnOStjVp"},"execution_count":null,"outputs":[]}]}